<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>
 -->
  <title>Nikita Dhawan</title>
  
  <meta name="author" content="Nikita Dhawan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!--   <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Nikita Dhawan</name>
              </p>
              <br>
              <p>I am an undergraduate senior at UC Berkeley, where I am studying Computer Science and Applied Mathematics. 
              </p>
              <p>
                I enjoy working on research problems at the <a href="http://rail.eecs.berkeley.edu/">Robotics and AI Lab</a> @ <a href="https://bair.berkeley.edu/">BAIR</a>, 
                under the mentorship of <a href="http://marvinzhang.com/">Marvin Zhang</a> and <a href="http://people.eecs.berkeley.edu/~svlevine/">Professor Sergey Levine</a>.
              </p>
              <br>

              <p style="text-align:center">
                <a href="mailto:nikitadhawan@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/nikita-dhawan-7a4a29149/">LinkedIn</a> 
<!--                 &nbsp/&nbsp -->
<!--                 <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
<!--                 <a href="https://www.facebook.com/barron.jon">Facebook</a> &nbsp/&nbsp -->
<!--                 <a href="https://twitter.com/jon_barron">Twitter</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Nikita.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Nikita.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in developing reliable machine learning algorithms with a focus on meta-learning and reinforcement learning.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
<!--           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='avid.png' width="160">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td> -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/avid.png" alt="avid">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1912.04443">
                <papertitle>AVID: Learning Multi-Stage Tasks via Pixel-Level Translation of Human Videos</papertitle>
              </a>
              <br>
              <a href="https://lauramsmith.github.io/">Laura Smith</a>,
              <strong>Nikita Dhawan</strong>,
              <a href="http://marvinzhang.com/">Marvin Zhang</a>,
              <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>,
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>,
              <br>
              <em>RSS</em>, 2020  
              <br>
              <a href="https://sites.google.com/view/rss20avid">website</a> /
              <a href="https://arxiv.org/abs/1912.04443">arXiv</a> /
              <a href="https://bair.berkeley.edu/blog/2019/12/13/humans-cyclegan/">blog</a>
              <p></p>
              <p>Robotic reinforcement learning (RL) holds the promise of enabling robots to learn complex behaviors through experience. 
                However, realizing this promise for long-horizon tasks in the real world requires mechanisms to reduce human burden in terms of defining the task and scaffolding the learning process. 
                In this paper, we study how these challenges can be alleviated with an automated robotic learning framework, 
                in which multi-stage tasks are defined simply by providing videos of a human demonstrator and then learned autonomously by the robot from raw image observations. 
                A central challenge in imitating human videos is the difference in appearance between the human and robot, which typically requires manual correspondence. 
                We instead take an automated approach and perform pixel-level image translation via CycleGAN to convert the human demonstration into a video of a robot, 
                which can then be used to construct a reward function for a model-based RL algorithm. 
                The robot then learns the task one stage at a time, automatically learning how to reset each stage to retry it multiple times without human-provided resets. 
                This makes the learning process largely automatic, from intuitive task specification via a video to automated training with minimal human intervention. 
                We demonstrate that our approach is capable of learning complex tasks, such as operating a coffee machine, directly from raw image observations, 
                requiring only 20 minutes to provide human demonstrations and about 180 minutes of robot interaction.</p>
            </td>
          </tr> 

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eecs126.png" alt="eecs126">
            </td>
            <td width="75%" valign="center">
              <strong>EECS 126: Probability and Random Processes</strong>
              <br>
              <a href="https://inst.eecs.berkeley.edu/~ee126/fa20/">Undergraduate Student Instructor, Fall 2020</a>
              <br>
              <a href="https://inst.eecs.berkeley.edu/~ee126/sp20/">Undergraduate Student Instructor, Spring 2020</a>
              <br>
              <a href="https://inst.eecs.berkeley.edu/~ee126/fa19/">Reader, Fall 2019</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eecs229a.png" alt="eecs229a">
            </td>
            <td width="75%" valign="center">
              <strong>EECS 229A: Information Theory and Coding</strong>
              <br>
              <a href="https://sites.google.com/view/eecs229a-fall20">Reader, Fall 2020</a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
